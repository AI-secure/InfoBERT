# InfoBERT: Improving Robustness of Language Models from An Information Theoretic Perspective 

This is the official code base for our ICLR 2021 paper:

["InfoBERT: Improving Robustness of Language Models from An Information Theoretic Perspective".](https://openreview.net/forum?id=hpH98mK5Puk)

Boxin Wang, Shuohang Wang, Yu Cheng, Zhe Gan, Ruoxi Jia, Bo Li, Jingjing Liu

## Usage
### Prepare your environment 

Download required packages
```
pip install -r requirements.txt
```
### ANLI and TextFooler
To run ANLI and TextFooler experiments, refer to README in the `ANLI` directory.

### SQuAD
We will upload the code for the SQuAD experiments soon. 
